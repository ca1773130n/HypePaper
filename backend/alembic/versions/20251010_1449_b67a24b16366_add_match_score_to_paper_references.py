"""add_match_score_to_paper_references

Revision ID: b67a24b16366
Revises: 001
Create Date: 2025-10-10 14:49:39.165899

"""
from typing import Sequence, Union

from alembic import op
import sqlalchemy as sa
from sqlalchemy.dialects import postgresql

# revision identifiers, used by Alembic.
revision: str = 'b67a24b16366'
down_revision: Union[str, None] = '001'
branch_labels: Union[str, Sequence[str], None] = None
depends_on: Union[str, Sequence[str], None] = None


def upgrade() -> None:
    # ### commands auto generated by Alembic - please adjust! ###
    op.create_table('admin_task_logs',
    sa.Column('id', sa.Uuid(), nullable=False),
    sa.Column('task_type', sa.String(length=50), nullable=False),
    sa.Column('task_params', sa.JSON(), nullable=True),
    sa.Column('status', sa.String(length=20), nullable=False),
    sa.Column('result', sa.JSON(), nullable=True),
    sa.Column('error', sa.Text(), nullable=True),
    sa.Column('created_at', sa.DateTime(timezone=True), nullable=False),
    sa.Column('completed_at', sa.DateTime(timezone=True), nullable=True),
    sa.PrimaryKeyConstraint('id')
    )
    op.create_table('authors',
    sa.Column('id', sa.Integer(), autoincrement=True, nullable=False),
    sa.Column('name', sa.String(length=200), nullable=False, comment='Full author name (normalized)'),
    sa.Column('affiliations', postgresql.JSONB(astext_type=sa.Text()), nullable=True, comment="List of institutions: ['MIT', 'Stanford', ...]"),
    sa.Column('countries', postgresql.JSONB(astext_type=sa.Text()), nullable=True, comment="List of countries: ['USA', 'UK', ...]"),
    sa.Column('paper_count', sa.Integer(), server_default=sa.text('0'), nullable=False, comment='Total papers authored'),
    sa.Column('created_at', sa.DateTime(), server_default=sa.text('NOW()'), nullable=False),
    sa.Column('updated_at', sa.DateTime(), server_default=sa.text('NOW()'), nullable=False),
    sa.PrimaryKeyConstraint('id')
    )
    op.create_index('idx_authors_affiliations_gin', 'authors', ['affiliations'], unique=False, postgresql_using='gin')
    op.create_index('idx_authors_name_fts', 'authors', [sa.text("to_tsvector('english', name)")], unique=False, postgresql_using='gin')
    op.create_index(op.f('ix_authors_name'), 'authors', ['name'], unique=True)
    op.create_table('github_metrics',
    sa.Column('paper_id', sa.UUID(), nullable=False),
    sa.Column('repository_url', sa.String(length=500), nullable=False, comment='GitHub repository URL'),
    sa.Column('repository_owner', sa.String(length=100), nullable=False, comment='Repository owner (user/org)'),
    sa.Column('repository_name', sa.String(length=200), nullable=False, comment='Repository name'),
    sa.Column('current_stars', sa.Integer(), server_default=sa.text('0'), nullable=False, comment='Current star count'),
    sa.Column('current_forks', sa.Integer(), server_default=sa.text('0'), nullable=False, comment='Current fork count'),
    sa.Column('current_watchers', sa.Integer(), server_default=sa.text('0'), nullable=False, comment='Current watcher count'),
    sa.Column('primary_language', sa.String(length=50), nullable=True, comment='Primary programming language'),
    sa.Column('repository_description', sa.Text(), nullable=True, comment='Repository description'),
    sa.Column('repository_created_at', sa.DateTime(), nullable=True, comment='Repository creation date'),
    sa.Column('repository_updated_at', sa.DateTime(), nullable=True, comment='Last repository update'),
    sa.Column('average_hype', sa.Float(), nullable=True, comment='Average daily star gain (all-time)'),
    sa.Column('weekly_hype', sa.Float(), nullable=True, comment='Star gain in last 7 days'),
    sa.Column('monthly_hype', sa.Float(), nullable=True, comment='Star gain in last 30 days'),
    sa.Column('tracking_start_date', sa.Date(), nullable=False, comment='Date when tracking began'),
    sa.Column('last_tracked_at', sa.DateTime(), server_default=sa.text('NOW()'), nullable=False, comment='Last successful tracking timestamp'),
    sa.Column('tracking_enabled', sa.Boolean(), server_default=sa.text('true'), nullable=False, comment='Enable/disable tracking'),
    sa.Column('created_at', sa.DateTime(), server_default=sa.text('NOW()'), nullable=False),
    sa.Column('updated_at', sa.DateTime(), server_default=sa.text('NOW()'), nullable=False),
    sa.ForeignKeyConstraint(['paper_id'], ['papers.id'], ondelete='CASCADE'),
    sa.PrimaryKeyConstraint('paper_id')
    )
    op.create_index('idx_github_metrics_monthly_hype', 'github_metrics', ['monthly_hype'], unique=False, postgresql_ops={'monthly_hype': 'DESC'})
    op.create_index('idx_github_metrics_owner', 'github_metrics', ['repository_owner'], unique=False)
    op.create_index('idx_github_metrics_stars', 'github_metrics', ['current_stars'], unique=False, postgresql_ops={'current_stars': 'DESC'})
    op.create_index('idx_github_metrics_weekly_hype', 'github_metrics', ['weekly_hype'], unique=False, postgresql_ops={'weekly_hype': 'DESC'})
    op.create_index(op.f('ix_github_metrics_current_stars'), 'github_metrics', ['current_stars'], unique=False)
    op.create_index(op.f('ix_github_metrics_monthly_hype'), 'github_metrics', ['monthly_hype'], unique=False)
    op.create_index(op.f('ix_github_metrics_repository_owner'), 'github_metrics', ['repository_owner'], unique=False)
    op.create_index(op.f('ix_github_metrics_repository_url'), 'github_metrics', ['repository_url'], unique=True)
    op.create_index(op.f('ix_github_metrics_weekly_hype'), 'github_metrics', ['weekly_hype'], unique=False)
    op.create_table('llm_extractions',
    sa.Column('id', sa.Integer(), autoincrement=True, nullable=False),
    sa.Column('paper_id', sa.UUID(), nullable=False),
    sa.Column('extraction_type', sa.Enum('TASK', 'METHOD', 'DATASET', 'METRIC', 'LIMITATION', 'COMPARISON', name='extractiontype'), nullable=False, comment='Type of metadata extracted'),
    sa.Column('primary_value', sa.Text(), nullable=True, comment='Primary extracted value'),
    sa.Column('secondary_value', sa.Text(), nullable=True, comment='Secondary extracted value'),
    sa.Column('tertiary_value', sa.Text(), nullable=True, comment='Tertiary extracted value'),
    sa.Column('all_values', postgresql.JSONB(astext_type=sa.Text()), nullable=True, comment='All extracted values (for datasets/metrics)'),
    sa.Column('llm_provider', sa.String(length=50), nullable=False, comment="LLM provider: 'openai', 'llamacpp'"),
    sa.Column('llm_model', sa.String(length=100), nullable=False, comment="Model name: 'gpt-4', 'Polaris-7B-preview'"),
    sa.Column('prompt_version', sa.String(length=20), nullable=True, comment='Prompt template version for reproducibility'),
    sa.Column('raw_response', sa.Text(), nullable=True, comment='Raw LLM response for debugging'),
    sa.Column('verification_status', sa.Enum('PENDING_REVIEW', 'VERIFIED', 'REJECTED', 'AUTO_ACCEPTED', name='verificationstatus'), server_default=sa.text("'pending_review'"), nullable=False, comment='Manual verification state'),
    sa.Column('verified_by', sa.String(length=100), nullable=True, comment='Username of verifier'),
    sa.Column('verified_at', sa.DateTime(), nullable=True, comment='Verification timestamp'),
    sa.Column('verification_notes', sa.Text(), nullable=True, comment='Verifier notes or rejection reason'),
    sa.Column('extracted_at', sa.DateTime(), server_default=sa.text('NOW()'), nullable=False),
    sa.ForeignKeyConstraint(['paper_id'], ['papers.id'], ondelete='CASCADE'),
    sa.PrimaryKeyConstraint('id')
    )
    op.create_index('idx_llm_extractions_paper', 'llm_extractions', ['paper_id'], unique=False)
    op.create_index('idx_llm_extractions_pending', 'llm_extractions', ['verification_status'], unique=False, postgresql_where=sa.text("verification_status = 'pending_review'"))
    op.create_index('idx_llm_extractions_type_status', 'llm_extractions', ['extraction_type', 'verification_status'], unique=False)
    op.create_index(op.f('ix_llm_extractions_extraction_type'), 'llm_extractions', ['extraction_type'], unique=False)
    op.create_index(op.f('ix_llm_extractions_paper_id'), 'llm_extractions', ['paper_id'], unique=False)
    op.create_index(op.f('ix_llm_extractions_verification_status'), 'llm_extractions', ['verification_status'], unique=False)
    op.create_table('paper_authors',
    sa.Column('paper_id', sa.UUID(), nullable=False),
    sa.Column('author_id', sa.Integer(), nullable=False),
    sa.Column('position', sa.Integer(), nullable=False, comment='Author position (1 = first author)'),
    sa.Column('affiliation_snapshot', sa.String(length=500), nullable=True, comment='Author affiliation for this specific paper'),
    sa.Column('created_at', sa.DateTime(), server_default=sa.text('NOW()'), nullable=False),
    sa.ForeignKeyConstraint(['author_id'], ['authors.id'], ondelete='CASCADE'),
    sa.ForeignKeyConstraint(['paper_id'], ['papers.id'], ondelete='CASCADE'),
    sa.PrimaryKeyConstraint('paper_id', 'author_id')
    )
    op.create_index('idx_paper_authors_author', 'paper_authors', ['author_id'], unique=False)
    op.create_index('idx_paper_authors_paper', 'paper_authors', ['paper_id'], unique=False)
    op.create_table('pdf_contents',
    sa.Column('paper_id', sa.UUID(), nullable=False),
    sa.Column('full_text', sa.Text(), nullable=False, comment='Complete extracted text from PDF'),
    sa.Column('references_text', sa.Text(), nullable=True, comment='Raw text from References/Bibliography section'),
    sa.Column('parsed_references', postgresql.JSONB(astext_type=sa.Text()), nullable=True, comment='List of parsed citation strings'),
    sa.Column('table_count', sa.Integer(), server_default=sa.text('0'), nullable=False, comment='Number of tables extracted'),
    sa.Column('table_csv_paths', postgresql.JSONB(astext_type=sa.Text()), nullable=True, comment="List of CSV file paths: ['paper.table00.csv', ...]"),
    sa.Column('extraction_method', sa.String(length=50), nullable=False, comment="PDF parser used: 'pymupdf', 'pdfplumber'"),
    sa.Column('table_extraction_method', sa.String(length=50), nullable=True, comment="Table extractor used: 'gmft', 'camelot'"),
    sa.Column('extraction_success', sa.Boolean(), server_default=sa.text('true'), nullable=False, comment='Whether extraction succeeded'),
    sa.Column('extraction_errors', postgresql.JSONB(astext_type=sa.Text()), nullable=True, comment='List of error messages if extraction failed'),
    sa.Column('pymupdf_version', sa.String(length=20), nullable=True, comment='PyMuPDF version used'),
    sa.Column('gmft_version', sa.String(length=20), nullable=True, comment='GMFT version used for table extraction'),
    sa.Column('extracted_at', sa.DateTime(), server_default=sa.text('NOW()'), nullable=False, comment='When PDF was processed'),
    sa.ForeignKeyConstraint(['paper_id'], ['papers.id'], ondelete='CASCADE'),
    sa.PrimaryKeyConstraint('paper_id')
    )
    op.create_index('idx_pdf_contents_fulltext_fts', 'pdf_contents', [sa.text("to_tsvector('english', full_text)")], unique=False, postgresql_using='gin')
    op.create_index('idx_pdf_contents_references_fts', 'pdf_contents', [sa.text("to_tsvector('english', references_text)")], unique=False, postgresql_using='gin')
    op.create_table('github_star_snapshots',
    sa.Column('paper_id', sa.UUID(), nullable=False),
    sa.Column('snapshot_date', sa.Date(), nullable=False, comment='Date of snapshot (UTC)'),
    sa.Column('star_count', sa.Integer(), nullable=False, comment='Star count at snapshot time'),
    sa.Column('fork_count', sa.Integer(), nullable=False, comment='Fork count at snapshot time'),
    sa.Column('watcher_count', sa.Integer(), nullable=False, comment='Watcher count at snapshot time'),
    sa.Column('stars_gained_since_yesterday', sa.Integer(), nullable=True, comment='Star delta from previous day'),
    sa.Column('created_at', sa.DateTime(), server_default=sa.text('NOW()'), nullable=False),
    sa.ForeignKeyConstraint(['paper_id'], ['github_metrics.paper_id'], ondelete='CASCADE'),
    sa.PrimaryKeyConstraint('paper_id', 'snapshot_date')
    )
    op.create_index('idx_star_snapshots_date', 'github_star_snapshots', ['snapshot_date'], unique=False, postgresql_ops={'snapshot_date': 'DESC'})
    op.create_index('idx_star_snapshots_paper_date', 'github_star_snapshots', ['paper_id', 'snapshot_date'], unique=False)
    op.drop_index('idx_hype_scores_date', table_name='hype_scores')
    op.drop_index('idx_hype_scores_paper_id', table_name='hype_scores')
    op.drop_table('hype_scores')
    op.alter_column('metric_snapshots', 'created_at',
               existing_type=postgresql.TIMESTAMP(timezone=True),
               type_=sa.DateTime(),
               existing_nullable=False,
               existing_server_default=sa.text('now()'))
    op.drop_index('idx_metric_snapshots_date', table_name='metric_snapshots')
    op.drop_index('idx_metric_snapshots_paper_date', table_name='metric_snapshots')
    op.drop_index('idx_metric_snapshots_paper_id', table_name='metric_snapshots')
    op.add_column('paper_references', sa.Column('paper_id', sa.UUID(), nullable=False, comment='Paper containing the citation'))
    op.add_column('paper_references', sa.Column('reference_id', sa.UUID(), nullable=False, comment='Paper being cited'))
    op.add_column('paper_references', sa.Column('reference_text', sa.Text(), nullable=True, comment='Original citation string from PDF References section'))
    op.add_column('paper_references', sa.Column('match_score', sa.Float(), nullable=True, comment='Levenshtein similarity score (0-100)'))
    op.add_column('paper_references', sa.Column('match_method', sa.String(length=50), nullable=True, comment="Matching method: 'exact', 'fuzzy_title', 'fuzzy_title_year'"))
    op.add_column('paper_references', sa.Column('verified_at', sa.DateTime(), nullable=True, comment='Manual verification timestamp'))
    op.alter_column('paper_references', 'created_at',
               existing_type=postgresql.TIMESTAMP(timezone=True),
               type_=sa.DateTime(),
               existing_nullable=False,
               existing_server_default=sa.text('now()'))
    op.drop_index('idx_paper_references_source', table_name='paper_references')
    op.drop_index('idx_paper_references_target', table_name='paper_references')
    op.drop_constraint('unique_source_target_pair', 'paper_references', type_='unique')
    op.create_index('idx_citations_match_score', 'paper_references', ['match_score'], unique=False, postgresql_ops={'match_score': 'DESC'})
    op.create_index('idx_citations_paper', 'paper_references', ['paper_id'], unique=False)
    op.create_index('idx_citations_reference', 'paper_references', ['reference_id'], unique=False)
    op.drop_constraint('paper_references_target_paper_id_fkey', 'paper_references', type_='foreignkey')
    op.drop_constraint('paper_references_source_paper_id_fkey', 'paper_references', type_='foreignkey')
    op.create_foreign_key(None, 'paper_references', 'papers', ['reference_id'], ['id'], ondelete='CASCADE')
    op.create_foreign_key(None, 'paper_references', 'papers', ['paper_id'], ['id'], ondelete='CASCADE')
    op.drop_column('paper_references', 'target_paper_id')
    op.drop_column('paper_references', 'target_title')
    op.drop_column('paper_references', 'source_paper_id')
    op.drop_column('paper_references', 'target_year')
    op.drop_column('paper_references', 'target_authors')
    op.drop_column('paper_references', 'id')
    op.alter_column('paper_topic_matches', 'matched_at',
               existing_type=postgresql.TIMESTAMP(timezone=True),
               type_=sa.DateTime(),
               existing_nullable=False,
               existing_server_default=sa.text('now()'))
    op.drop_index('idx_paper_topic_matches_paper', table_name='paper_topic_matches')
    op.drop_index('idx_paper_topic_matches_topic', table_name='paper_topic_matches')
    op.create_index('idx_paper_topic_matches_topic', 'paper_topic_matches', ['topic_id', 'relevance_score'], unique=False, postgresql_ops={'relevance_score': 'DESC'})
    op.create_index(op.f('ix_paper_topic_matches_paper_id'), 'paper_topic_matches', ['paper_id'], unique=False)
    op.add_column('papers', sa.Column('legacy_id', sa.String(length=100), nullable=True, comment='SHA256 hash of normalized(title + year) for deduplication'))
    op.add_column('papers', sa.Column('affiliations', postgresql.JSONB(astext_type=sa.Text()), nullable=True, comment='Author affiliations: {author_name: [institutions]}'))
    op.add_column('papers', sa.Column('affiliations_country', postgresql.JSONB(astext_type=sa.Text()), nullable=True, comment='Country extraction from affiliations: {author_name: [countries]}'))
    op.add_column('papers', sa.Column('year', sa.Integer(), nullable=True, comment='Publication year extracted from published_date'))
    op.add_column('papers', sa.Column('pages', postgresql.JSONB(astext_type=sa.Text()), nullable=True, comment='Page range: {start: int, end: int, total: int}'))
    op.add_column('papers', sa.Column('paper_type', sa.String(length=50), nullable=True, comment="Paper type: 'oral', 'poster', 'spotlight', 'workshop'"))
    op.add_column('papers', sa.Column('session_type', sa.String(length=100), nullable=True, comment='Conference session category'))
    op.add_column('papers', sa.Column('accept_status', sa.String(length=50), nullable=True, comment="Acceptance status: 'accepted', 'rejected', 'pending'"))
    op.add_column('papers', sa.Column('note', sa.Text(), nullable=True, comment='Additional notes or annotations'))
    op.add_column('papers', sa.Column('bibtex', sa.Text(), nullable=True, comment='BibTeX citation entry'))
    op.add_column('papers', sa.Column('primary_task', sa.String(length=200), nullable=True, comment="Primary research task (e.g., 'Image Classification')"))
    op.add_column('papers', sa.Column('secondary_task', sa.String(length=200), nullable=True, comment='Secondary research task if applicable'))
    op.add_column('papers', sa.Column('tertiary_task', sa.String(length=200), nullable=True, comment='Tertiary research task if applicable'))
    op.add_column('papers', sa.Column('primary_method', sa.String(length=200), nullable=True, comment="Primary method used (e.g., 'Convolutional Neural Network')"))
    op.add_column('papers', sa.Column('secondary_method', sa.String(length=200), nullable=True, comment='Secondary method if applicable'))
    op.add_column('papers', sa.Column('tertiary_method', sa.String(length=200), nullable=True, comment='Tertiary method if applicable'))
    op.add_column('papers', sa.Column('datasets_used', postgresql.JSONB(astext_type=sa.Text()), nullable=True, comment="Datasets mentioned: ['ImageNet', 'COCO', ...]"))
    op.add_column('papers', sa.Column('metrics_used', postgresql.JSONB(astext_type=sa.Text()), nullable=True, comment="Evaluation metrics: ['Accuracy', 'F1-Score', ...]"))
    op.add_column('papers', sa.Column('comparisons', postgresql.JSONB(astext_type=sa.Text()), nullable=True, comment='Comparison results: {baseline: score, proposed: score}'))
    op.add_column('papers', sa.Column('limitations', sa.Text(), nullable=True, comment='Paper limitations extracted by LLM'))
    op.add_column('papers', sa.Column('youtube_url', sa.String(length=500), nullable=True, comment='YouTube video URL (presentation/demo)'))
    op.add_column('papers', sa.Column('project_page_url', sa.String(length=500), nullable=True, comment='Official project page URL'))
    op.add_column('papers', sa.Column('github_star_tracking_start_date', sa.Date(), nullable=True, comment='Date when star tracking began'))
    op.add_column('papers', sa.Column('github_star_tracking_latest_footprint', postgresql.JSONB(astext_type=sa.Text()), nullable=True, comment='Latest tracking snapshot: {date: str, stars: int}'))
    op.alter_column('papers', 'created_at',
               existing_type=postgresql.TIMESTAMP(timezone=True),
               type_=sa.DateTime(),
               existing_nullable=False,
               existing_server_default=sa.text('now()'))
    op.alter_column('papers', 'updated_at',
               existing_type=postgresql.TIMESTAMP(timezone=True),
               type_=sa.DateTime(),
               existing_nullable=False,
               existing_server_default=sa.text('now()'))
    op.drop_index('idx_papers_arxiv_id', table_name='papers')
    op.drop_index('idx_papers_doi', table_name='papers')
    op.drop_index('idx_papers_sotapapers_id', table_name='papers')
    op.drop_constraint('uq_papers_arxiv_id', 'papers', type_='unique')
    op.drop_constraint('uq_papers_doi', 'papers', type_='unique')
    op.drop_constraint('uq_papers_sotapapers_id', 'papers', type_='unique')
    op.drop_index('idx_papers_published_date', table_name='papers')
    op.create_index('idx_papers_published_date', 'papers', ['published_date'], unique=False, postgresql_ops={'published_date': 'DESC'})
    op.create_index('idx_papers_abstract_fts', 'papers', [sa.text("to_tsvector('english', abstract)")], unique=False, postgresql_using='gin')
    op.create_index('idx_papers_affiliations_gin', 'papers', ['affiliations'], unique=False, postgresql_using='gin')
    op.create_index('idx_papers_datasets_gin', 'papers', ['datasets_used'], unique=False, postgresql_using='gin')
    op.create_index('idx_papers_metrics_gin', 'papers', ['metrics_used'], unique=False, postgresql_using='gin')
    op.create_index('idx_papers_task_year', 'papers', ['primary_task', 'year'], unique=False)
    op.create_index('idx_papers_year_desc', 'papers', ['year'], unique=False, postgresql_ops={'year': 'DESC'})
    op.create_index(op.f('ix_papers_arxiv_id'), 'papers', ['arxiv_id'], unique=True)
    op.create_index(op.f('ix_papers_doi'), 'papers', ['doi'], unique=True)
    op.create_index(op.f('ix_papers_legacy_id'), 'papers', ['legacy_id'], unique=True)
    op.create_index(op.f('ix_papers_primary_task'), 'papers', ['primary_task'], unique=False)
    op.create_index(op.f('ix_papers_year'), 'papers', ['year'], unique=False)
    op.drop_column('papers', 'pdf_local_path')
    op.drop_column('papers', 'reference_count')
    op.drop_column('papers', 'sotapapers_url')
    op.drop_column('papers', 'references_extracted')
    op.drop_column('papers', 'sotapapers_id')
    op.alter_column('topics', 'created_at',
               existing_type=postgresql.TIMESTAMP(timezone=True),
               type_=sa.DateTime(),
               existing_nullable=False,
               existing_server_default=sa.text('now()'))
    op.drop_index('idx_topics_is_system', table_name='topics')
    op.drop_index('idx_topics_user_id', table_name='topics')
    # ### end Alembic commands ###


def downgrade() -> None:
    # ### commands auto generated by Alembic - please adjust! ###
    op.create_index('idx_topics_user_id', 'topics', ['user_id'], unique=False)
    op.create_index('idx_topics_is_system', 'topics', ['is_system'], unique=False)
    op.alter_column('topics', 'created_at',
               existing_type=sa.DateTime(),
               type_=postgresql.TIMESTAMP(timezone=True),
               existing_nullable=False,
               existing_server_default=sa.text('now()'))
    op.add_column('papers', sa.Column('sotapapers_id', sa.VARCHAR(length=100), autoincrement=False, nullable=True))
    op.add_column('papers', sa.Column('references_extracted', sa.BOOLEAN(), server_default=sa.text('false'), autoincrement=False, nullable=False))
    op.add_column('papers', sa.Column('sotapapers_url', sa.VARCHAR(length=500), autoincrement=False, nullable=True))
    op.add_column('papers', sa.Column('reference_count', sa.INTEGER(), autoincrement=False, nullable=True))
    op.add_column('papers', sa.Column('pdf_local_path', sa.VARCHAR(length=1000), autoincrement=False, nullable=True))
    op.drop_index(op.f('ix_papers_year'), table_name='papers')
    op.drop_index(op.f('ix_papers_primary_task'), table_name='papers')
    op.drop_index(op.f('ix_papers_legacy_id'), table_name='papers')
    op.drop_index(op.f('ix_papers_doi'), table_name='papers')
    op.drop_index(op.f('ix_papers_arxiv_id'), table_name='papers')
    op.drop_index('idx_papers_year_desc', table_name='papers', postgresql_ops={'year': 'DESC'})
    op.drop_index('idx_papers_task_year', table_name='papers')
    op.drop_index('idx_papers_metrics_gin', table_name='papers', postgresql_using='gin')
    op.drop_index('idx_papers_datasets_gin', table_name='papers', postgresql_using='gin')
    op.drop_index('idx_papers_affiliations_gin', table_name='papers', postgresql_using='gin')
    op.drop_index('idx_papers_abstract_fts', table_name='papers', postgresql_using='gin')
    op.drop_index('idx_papers_published_date', table_name='papers', postgresql_ops={'published_date': 'DESC'})
    op.create_index('idx_papers_published_date', 'papers', [sa.text('published_date DESC')], unique=False)
    op.create_unique_constraint('uq_papers_sotapapers_id', 'papers', ['sotapapers_id'])
    op.create_unique_constraint('uq_papers_doi', 'papers', ['doi'])
    op.create_unique_constraint('uq_papers_arxiv_id', 'papers', ['arxiv_id'])
    op.create_index('idx_papers_sotapapers_id', 'papers', ['sotapapers_id'], unique=False)
    op.create_index('idx_papers_doi', 'papers', ['doi'], unique=False)
    op.create_index('idx_papers_arxiv_id', 'papers', ['arxiv_id'], unique=False)
    op.alter_column('papers', 'updated_at',
               existing_type=sa.DateTime(),
               type_=postgresql.TIMESTAMP(timezone=True),
               existing_nullable=False,
               existing_server_default=sa.text('now()'))
    op.alter_column('papers', 'created_at',
               existing_type=sa.DateTime(),
               type_=postgresql.TIMESTAMP(timezone=True),
               existing_nullable=False,
               existing_server_default=sa.text('now()'))
    op.drop_column('papers', 'github_star_tracking_latest_footprint')
    op.drop_column('papers', 'github_star_tracking_start_date')
    op.drop_column('papers', 'project_page_url')
    op.drop_column('papers', 'youtube_url')
    op.drop_column('papers', 'limitations')
    op.drop_column('papers', 'comparisons')
    op.drop_column('papers', 'metrics_used')
    op.drop_column('papers', 'datasets_used')
    op.drop_column('papers', 'tertiary_method')
    op.drop_column('papers', 'secondary_method')
    op.drop_column('papers', 'primary_method')
    op.drop_column('papers', 'tertiary_task')
    op.drop_column('papers', 'secondary_task')
    op.drop_column('papers', 'primary_task')
    op.drop_column('papers', 'bibtex')
    op.drop_column('papers', 'note')
    op.drop_column('papers', 'accept_status')
    op.drop_column('papers', 'session_type')
    op.drop_column('papers', 'paper_type')
    op.drop_column('papers', 'pages')
    op.drop_column('papers', 'year')
    op.drop_column('papers', 'affiliations_country')
    op.drop_column('papers', 'affiliations')
    op.drop_column('papers', 'legacy_id')
    op.drop_index(op.f('ix_paper_topic_matches_paper_id'), table_name='paper_topic_matches')
    op.drop_index('idx_paper_topic_matches_topic', table_name='paper_topic_matches', postgresql_ops={'relevance_score': 'DESC'})
    op.create_index('idx_paper_topic_matches_topic', 'paper_topic_matches', ['topic_id', sa.text('relevance_score DESC')], unique=False)
    op.create_index('idx_paper_topic_matches_paper', 'paper_topic_matches', ['paper_id'], unique=False)
    op.alter_column('paper_topic_matches', 'matched_at',
               existing_type=sa.DateTime(),
               type_=postgresql.TIMESTAMP(timezone=True),
               existing_nullable=False,
               existing_server_default=sa.text('now()'))
    op.add_column('paper_references', sa.Column('id', sa.UUID(), server_default=sa.text('gen_random_uuid()'), autoincrement=False, nullable=False))
    op.add_column('paper_references', sa.Column('target_authors', postgresql.ARRAY(sa.TEXT()), autoincrement=False, nullable=True))
    op.add_column('paper_references', sa.Column('target_year', sa.INTEGER(), autoincrement=False, nullable=True))
    op.add_column('paper_references', sa.Column('source_paper_id', sa.UUID(), autoincrement=False, nullable=False))
    op.add_column('paper_references', sa.Column('target_title', sa.VARCHAR(length=500), autoincrement=False, nullable=False))
    op.add_column('paper_references', sa.Column('target_paper_id', sa.UUID(), autoincrement=False, nullable=True))
    op.drop_constraint(None, 'paper_references', type_='foreignkey')
    op.drop_constraint(None, 'paper_references', type_='foreignkey')
    op.create_foreign_key('paper_references_source_paper_id_fkey', 'paper_references', 'papers', ['source_paper_id'], ['id'], ondelete='CASCADE')
    op.create_foreign_key('paper_references_target_paper_id_fkey', 'paper_references', 'papers', ['target_paper_id'], ['id'], ondelete='CASCADE')
    op.drop_index('idx_citations_reference', table_name='paper_references')
    op.drop_index('idx_citations_paper', table_name='paper_references')
    op.drop_index('idx_citations_match_score', table_name='paper_references', postgresql_ops={'match_score': 'DESC'})
    op.create_unique_constraint('unique_source_target_pair', 'paper_references', ['source_paper_id', 'target_title'])
    op.create_index('idx_paper_references_target', 'paper_references', ['target_paper_id'], unique=False)
    op.create_index('idx_paper_references_source', 'paper_references', ['source_paper_id'], unique=False)
    op.alter_column('paper_references', 'created_at',
               existing_type=sa.DateTime(),
               type_=postgresql.TIMESTAMP(timezone=True),
               existing_nullable=False,
               existing_server_default=sa.text('now()'))
    op.drop_column('paper_references', 'verified_at')
    op.drop_column('paper_references', 'match_method')
    op.drop_column('paper_references', 'match_score')
    op.drop_column('paper_references', 'reference_text')
    op.drop_column('paper_references', 'reference_id')
    op.drop_column('paper_references', 'paper_id')
    op.create_index('idx_metric_snapshots_paper_id', 'metric_snapshots', ['paper_id'], unique=False)
    op.create_index('idx_metric_snapshots_paper_date', 'metric_snapshots', ['paper_id', sa.text('snapshot_date DESC')], unique=False)
    op.create_index('idx_metric_snapshots_date', 'metric_snapshots', [sa.text('snapshot_date DESC')], unique=False)
    op.alter_column('metric_snapshots', 'created_at',
               existing_type=sa.DateTime(),
               type_=postgresql.TIMESTAMP(timezone=True),
               existing_nullable=False,
               existing_server_default=sa.text('now()'))
    op.create_table('hype_scores',
    sa.Column('paper_id', sa.UUID(), autoincrement=False, nullable=False),
    sa.Column('score_date', sa.DATE(), autoincrement=False, nullable=False),
    sa.Column('total_score', sa.DOUBLE_PRECISION(precision=53), autoincrement=False, nullable=False),
    sa.Column('star_growth_score', sa.DOUBLE_PRECISION(precision=53), autoincrement=False, nullable=True),
    sa.Column('citation_growth_score', sa.DOUBLE_PRECISION(precision=53), autoincrement=False, nullable=True),
    sa.Column('absolute_score', sa.DOUBLE_PRECISION(precision=53), autoincrement=False, nullable=True),
    sa.Column('recency_score', sa.DOUBLE_PRECISION(precision=53), autoincrement=False, nullable=True),
    sa.Column('created_at', postgresql.TIMESTAMP(timezone=True), server_default=sa.text('now()'), autoincrement=False, nullable=False),
    sa.ForeignKeyConstraint(['paper_id'], ['papers.id'], name='hype_scores_paper_id_fkey', ondelete='CASCADE'),
    sa.PrimaryKeyConstraint('paper_id', 'score_date', name='pk_hype_scores')
    )
    op.create_index('idx_hype_scores_paper_id', 'hype_scores', ['paper_id'], unique=False)
    op.create_index('idx_hype_scores_date', 'hype_scores', [sa.text('score_date DESC')], unique=False)
    op.drop_index('idx_star_snapshots_paper_date', table_name='github_star_snapshots')
    op.drop_index('idx_star_snapshots_date', table_name='github_star_snapshots', postgresql_ops={'snapshot_date': 'DESC'})
    op.drop_table('github_star_snapshots')
    op.drop_index('idx_pdf_contents_references_fts', table_name='pdf_contents', postgresql_using='gin')
    op.drop_index('idx_pdf_contents_fulltext_fts', table_name='pdf_contents', postgresql_using='gin')
    op.drop_table('pdf_contents')
    op.drop_index('idx_paper_authors_paper', table_name='paper_authors')
    op.drop_index('idx_paper_authors_author', table_name='paper_authors')
    op.drop_table('paper_authors')
    op.drop_index(op.f('ix_llm_extractions_verification_status'), table_name='llm_extractions')
    op.drop_index(op.f('ix_llm_extractions_paper_id'), table_name='llm_extractions')
    op.drop_index(op.f('ix_llm_extractions_extraction_type'), table_name='llm_extractions')
    op.drop_index('idx_llm_extractions_type_status', table_name='llm_extractions')
    op.drop_index('idx_llm_extractions_pending', table_name='llm_extractions', postgresql_where=sa.text("verification_status = 'pending_review'"))
    op.drop_index('idx_llm_extractions_paper', table_name='llm_extractions')
    op.drop_table('llm_extractions')
    op.drop_index(op.f('ix_github_metrics_weekly_hype'), table_name='github_metrics')
    op.drop_index(op.f('ix_github_metrics_repository_url'), table_name='github_metrics')
    op.drop_index(op.f('ix_github_metrics_repository_owner'), table_name='github_metrics')
    op.drop_index(op.f('ix_github_metrics_monthly_hype'), table_name='github_metrics')
    op.drop_index(op.f('ix_github_metrics_current_stars'), table_name='github_metrics')
    op.drop_index('idx_github_metrics_weekly_hype', table_name='github_metrics', postgresql_ops={'weekly_hype': 'DESC'})
    op.drop_index('idx_github_metrics_stars', table_name='github_metrics', postgresql_ops={'current_stars': 'DESC'})
    op.drop_index('idx_github_metrics_owner', table_name='github_metrics')
    op.drop_index('idx_github_metrics_monthly_hype', table_name='github_metrics', postgresql_ops={'monthly_hype': 'DESC'})
    op.drop_table('github_metrics')
    op.drop_index(op.f('ix_authors_name'), table_name='authors')
    op.drop_index('idx_authors_name_fts', table_name='authors', postgresql_using='gin')
    op.drop_index('idx_authors_affiliations_gin', table_name='authors', postgresql_using='gin')
    op.drop_table('authors')
    op.drop_table('admin_task_logs')
    # ### end Alembic commands ###
